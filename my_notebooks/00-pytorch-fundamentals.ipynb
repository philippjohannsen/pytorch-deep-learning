{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca140c7-cf6a-4b8b-8dde-ae7027d51952",
   "metadata": {},
   "source": [
    "# 00. PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03db5b7e-2d6f-4436-8205-fa6b248b7623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7acaa-a34e-4b81-8412-edeac129bdf1",
   "metadata": {},
   "source": [
    "## Introduction to Tensors in PyTorch\n",
    "\n",
    "### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b09e5b-8632-4612-be8c-a50d51e1a183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(3)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95a6c7b-7806-425c-b9fb-ca7f8a2aabbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae23b64a-bbdb-41cb-a274-d18642565cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a79b696-39a7-4711-bbfe-d92b843b491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "# Converts element to scalar. Cannot be used on higher ndmim objects\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd7a3e2-c1ec-4a21-bc5f-e90818fb93b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([1,2])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b36d690-5433-42bc-a989-129c60e6f3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of dimension (ndim) corresponds to number of square brackets\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "920c0315-7e4e-44f6-8698-e3340be62792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing\n",
    "vector[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e838d47a-6f1d-420d-bdce-f01e39d76b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "# For simplicity use numpy to create a 3x3 array for torch.tensor to use\n",
    "arr = np.arange(0,9).reshape(3,3)\n",
    "matrix = torch.tensor(arr)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57eff2d3-7532-4449-82df-f7193fd0e593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e3bbee0-0296-4d76-b07c-479ecf7efec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d5cd2e-52d4-4d6e-8da5-73082927213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3625d5b2-61c0-4991-b71b-792bf4276978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce40a060-0830-4ff0-bf7d-b01b21011dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "arr2 = np.arange(0,18).reshape(2,3,3)\n",
    "tensor = torch.tensor(arr2)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f6160d9-cdc4-4c22-8045-437497e511fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7356f105-0e2b-477f-82be-a6da2921776d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87fe0f08-c333-4c55-a430-0e7b2a99e2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([[[\n",
    "        [[0,  1,  2],\n",
    "         [ 3,  4,  5],\n",
    "         [ 6,  7,  8]],\n",
    "\n",
    "        [[ 9, 10, 11],\n",
    "         [12, 13, 14],\n",
    "         [15, 16, 17]]]]])\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06373a-9b02-4ce5-8a6c-4f9ef05bd237",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "Why random tensors? \n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed8e117b-2fe9-46ba-a89e-aa3dc6c5b683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2816, 0.4907, 0.4271, 0.1842],\n",
       "        [0.9431, 0.0707, 0.3918, 0.3404],\n",
       "        [0.5603, 0.7571, 0.7964, 0.5056]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64611b5e-e4ca-423e-804b-8d6fafbcf833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdd2d410-058c-4eb5-a509-e963a0b7dc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d004bfb3-8a88-48da-8a1a-a9a059953f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor \n",
    "random_image_size_tensor = torch.rand(size=(3, 224, 224)) # colour channels, height, width\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b215053-b0be-4a3e-be46-35026253d3c9",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8573f71e-5ced-4142-aacb-be138c1807cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeroes = torch.zeros(size=(3,4))\n",
    "zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4750df3a-1101-4fb4-914b-a48ee87f8bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4492d810-ce94-4ab4-81e0-3e491c5bf3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroes.dtype, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdac61b-12a0-49fd-aea7-6be82e4c0a2c",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f55a46a8-0e7d-4aa3-b423-cb53893fdb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(), returns a 1-D tensor\n",
    "torch.arange(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff14b681-05b3-4374-886e-38614e3cdc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,\n",
       "         28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,  52,  54,\n",
       "         56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,  80,  82,\n",
       "         84,  86,  88,  90,  92,  94,  96,  98, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=101, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6f5bc65-07e7-4ebf-9344-8ed1e2220911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[6.9193e+24, 3.0915e-41, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[2.7253e+20, 1.7728e+28, 1.4226e-13],\n",
      "         [6.2608e+22, 4.7428e+30, 7.7781e+31]],\n",
      "\n",
      "        [[1.8515e+28, 6.8794e+11, 2.7253e+20],\n",
      "         [3.0866e+29, 1.1824e+22, 7.0976e+22]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.4361, 0.8379, 0.4258],\n",
      "         [0.6417, 0.2052, 0.8083]],\n",
      "\n",
      "        [[0.3727, 0.6507, 0.3971],\n",
      "         [0.5283, 0.5204, 0.1976]]])\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "# Often, when you’re performing operations on two or more tensors, they will need to be of the same shape - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the torch.*_like() methods:\n",
    "x = torch.empty(2, 2, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "empty_like_x = torch.empty_like(x)\n",
    "print(empty_like_x.shape)\n",
    "print(empty_like_x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "print(zeros_like_x.shape)\n",
    "print(zeros_like_x)\n",
    "\n",
    "ones_like_x = torch.ones_like(x)\n",
    "print(ones_like_x.shape)\n",
    "print(ones_like_x)\n",
    "\n",
    "rand_like_x = torch.rand_like(x)\n",
    "print(rand_like_x.shape)\n",
    "print(rand_like_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15362f0-9c41-4e0e-b2a0-5b30fa954a74",
   "metadata": {},
   "source": [
    "### Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afde686b-4a7f-4916-9e60-765f853a50e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.]), torch.float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # what datatype is the tensor (e.g. float16 or float32)\n",
    "                               device=None, # what device the tensor is on (default is cpu; cuda is gpu)\n",
    "                               requires_grad=False # whether or not to track gradients with this tensors operations\n",
    "                              )\n",
    "\n",
    "float_32_tensor, float_32_tensor.dtype\n",
    "# dtype is float32 even though dtype=None -> float32 is default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c295e69-e65a-4346-a7bb-24114662190f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.], dtype=torch.float16), torch.float16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 16 tensor: sacrifice some detail of how the numbers are represented <-> calculate faster and take up less space in memory as compared to float 32\n",
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)\n",
    "float_16_tensor, float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966faf11-5bda-4cb1-957b-7c947812616f",
   "metadata": {},
   "source": [
    "The available datatypes in PyTorch are listed in https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9650027a-182e-4e1c-972c-1097e9ef3239",
   "metadata": {},
   "source": [
    "**Note**: Tensor datatypes is one of the 3 big errors encountered in PyTorch and deep learning:\n",
    "1. Tensor is not right datatype\n",
    "2. Tensor is not right shape\n",
    "3. Tensor is not on the right device\n",
    "\n",
    "Precision in computing: https://en.wikipedia.org/wiki/Precision_(computer_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "574fa8b6-7d19-4892-bfbc-655bb8cccd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor*float_16_tensor # not all operations throw an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b6313b1-8813-4ff5-918e-d0cf9943defb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5019a16f-b783-47aa-84f7-4a7368179a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor*int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c78e3-0623-4563-a4d9-94f9e83b0f88",
   "metadata": {},
   "source": [
    "### Getting attributes from tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5322d6-af4c-4f81-bc27-05faa53780dd",
   "metadata": {},
   "source": [
    "1. Tensor is not right datatype - to get datatype from a tensor, can use `tensor.dtype`\n",
    "2. Tensor is not right shape - to get shape from a tensor, can use `tensor.shape`\n",
    "3. Tensor is not on the right device - to get device from a tensor, can use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcf48faa-b86e-4a32-8598-7fd9891040c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2211, 0.6066, 0.8054, 0.2971],\n",
       "        [0.6062, 0.1424, 0.9666, 0.8330],\n",
       "        [0.2086, 0.4768, 0.5447, 0.2628]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bedb723e-19a3-422f-a795-686169b302c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2211, 0.6066, 0.8054, 0.2971],\n",
      "        [0.6062, 0.1424, 0.9666, 0.8330],\n",
      "        [0.2086, 0.4768, 0.5447, 0.2628]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Get  attributes from tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002bd6e-15d5-41ba-bf75-2eecf663d472",
   "metadata": {},
   "source": [
    "### Manipulating tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ade93ca-c20f-4b99-afd1-754db8b758ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ab4b607-0e7c-4a6c-8c54-804b4da11c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10 (element-wise)\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e04399d4-7cf9-49a2-bdb5-ef5db22242c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c255d4f9-c0dc-4f3d-9761-8e4978c68f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30])\n",
      "tensor([11, 12, 13])\n",
      "tensor([-9, -8, -7])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch has built-in functions\n",
    "print(torch.mul(tensor, 10))\n",
    "print(torch.add(tensor, 10))\n",
    "print(torch.subtract(tensor, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3700c8-b527-4744-960d-e513a3969cc9",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "\n",
    "1. Element-wise operation (scalar multiplication)\n",
    "2. Matrix multiplication\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3,2) @ (3,2)` won't work\n",
    "* `(2,3) @ (3,2)` will work\n",
    "* `(3,2) @ (2,3)` will work\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "* `(2,3) @ (3,2)` -> `(2,2)`\n",
    "* `(3,2) @ (2,3)` -> `(3,3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c6d5ef1-7bb3-4c6a-8fea-28ffab945ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc46da86-e23a-4cee-9001-5ee3423a43b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 541 µs, sys: 0 ns, total: 541 µs\n",
      "Wall time: 412 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "493cc9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 315 µs, sys: 62 µs, total: 377 µs\n",
      "Wall time: 313 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9c8a99c-2265-4c0f-80fa-aa6dc15d033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.97 ms, sys: 0 ns, total: 1.97 ms\n",
      "Wall time: 1.95 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dot_product = 0\n",
    "\n",
    "for i in range(tensor.shape[0]):\n",
    "    dot_product += tensor[i] * tensor[i]\n",
    "\n",
    "dot_product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4d01c",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24828b5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                         [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m      4\u001b[0m                         [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m                         [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m      8\u001b[0m                         [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(tensor_A, tensor_B) \u001b[38;5;66;03m# same as above; torch.mm is an alias for torch.matmul\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                        [8,11],\n",
    "                        [9,12]])\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B)\n",
    "torch.mm(tensor_A, tensor_B) # same as above; torch.mm is an alias for torch.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff51641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b9cf5",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can use the **transpose** `.T` to change the shape of tensor_B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "188aa905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92fd74e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96b45cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([2, 3])\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions must match\n",
      "Output:\n",
      "\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "\n",
      "Shape of output: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The matrix multiplication works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.T.shape}\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.mm(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(f\"\\nShape of output: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5e823",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b93e4821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89ee880f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5355fe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5eca849a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean - note: the torch.mean() function requires a tensor of float32 or float64 dtype to work\n",
    "torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34e5c1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(450)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad013a",
   "metadata": {},
   "source": [
    "### Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f715ed31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmin() -> returns index position of target tensor where the minimum value occurs\n",
    "torch.argmin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d83358ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positional maximum\n",
    "torch.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f06bd9a",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side-by-side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - ass a `1` dimension to a target tensor \n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0215d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6404f127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape (shape must be compatible with number of elements)\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d1a167cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(3,3)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011d0f4",
   "metadata": {},
   "source": [
    "Changing `z` changes `x` and vice versa (because a view of a tensor shares the same memory as the original tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7237e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3.],\n",
       "         [5., 5., 6.],\n",
       "         [5., 8., 9.]]),\n",
       " tensor([5., 2., 3., 5., 5., 6., 5., 8., 9.]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0047411a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.],\n",
       "         [99.,  5.,  6.],\n",
       "         [ 5.,  8.,  9.]]),\n",
       " tensor([ 5.,  2.,  3., 99.,  5.,  6.,  5.,  8.,  9.]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3] = 99\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d336e1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3., 99.,  5.,  6.,  5.,  8.,  9.],\n",
       "         [ 5.,  2.,  3., 99.,  5.,  6.,  5.,  8.,  9.],\n",
       "         [ 5.,  2.,  3., 99.,  5.,  6.,  5.,  8.,  9.]]),\n",
       " torch.Size([3, 9]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x])\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de371fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  5.,  5.],\n",
       "         [ 2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.],\n",
       "         [99., 99., 99.],\n",
       "         [ 5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.],\n",
       "         [ 5.,  5.,  5.],\n",
       "         [ 8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.]]),\n",
       " torch.Size([9, 3]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors next to each other\n",
    "x_stacked = torch.stack([x, x, x], dim=1)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze and unsqueeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztm_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
